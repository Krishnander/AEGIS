# =============================================================================
# AEGIS Environment Configuration
# =============================================================================
# Copy this file to .env.local and fill in your actual values
# DO NOT commit .env.local to git (it contains secrets)
# =============================================================================

# -----------------------------------------------------------------------------
# REQUIRED: HuggingFace Token (for MedGemma inference)
# -----------------------------------------------------------------------------
# Get your token from: https://huggingface.co/settings/tokens
# 1. Accept MedGemma license: https://huggingface.co/google/medgemma-1.5-4b-it
# 2. Create a Read token at Settings > Tokens
# This is used server-side via the Next.js API route â€” never exposed to browser.
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxx

# MedGemma model (default: google/medgemma-1.5-4b-it)
# MEDGEMMA_MODEL=google/medgemma-1.5-4b-it

# -----------------------------------------------------------------------------
# OPTIONAL: Kaggle Cloud Backend API URL
# -----------------------------------------------------------------------------
# If you're also running the Kaggle notebook (brain/medgemma_kaggle_server.ipynb):
# NEXT_PUBLIC_API_URL=https://your-ngrok-url.ngrok-free.app

# -----------------------------------------------------------------------------
# OPTIONAL: Feature Flags
# -----------------------------------------------------------------------------

# Demo mode: Always use demo data instead of real AI inference
NEXT_PUBLIC_DEMO_MODE=false

# Edge-only mode: Skip cloud fallback, use browser AI only
NEXT_PUBLIC_EDGE_ONLY=false

# Enable debug logging
NEXT_PUBLIC_DEBUG=false
